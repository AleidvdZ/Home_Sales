# Home_Sales
## Module_22 Challenge

The purpose of this challenge is to determine key metrics about home sales data and to use Spark to create temporary views, partition the data, cache and uncache a temporary table  

## Process and Resources  
### Timeline/Insights:  
1007 Downloaded files and started project  
1007 Completed project

### Files and Links used for Reference:  
Module 22 activities  

## Examples  
Examples of time it took for run:
Original:  
<img width="235" alt="original" src="https://github.com/AleidvdZ/Home_Sales/assets/131220504/c2688130-c823-4ff8-8262-5370549e6feb">  

Cached:  
<img width="229" alt="cached" src="https://github.com/AleidvdZ/Home_Sales/assets/131220504/11e9092a-4117-4b62-93e7-474e48555657">  

Partitioned:  
<img width="245" alt="partitioned" src="https://github.com/AleidvdZ/Home_Sales/assets/131220504/fe98117f-6521-4ab3-adaa-137ad34e076f">  

Proof of partinioning:  
<img width="250" alt="partitioning_files" src="https://github.com/AleidvdZ/Home_Sales/assets/131220504/6374b495-f300-4f4e-a2cc-d10417d2fcbf">  

## Installing  
From the starter code:  
import Spark and Java  

csv import from: https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/home_sales_revised.csv  

## Contributing  
Solo Challenge - Aleid van der Zel

